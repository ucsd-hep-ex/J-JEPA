{
    "activation": "gelu",
    "attn_dim": 1024,
    "attn_drop": 0.0,
    "base_momentum": 0.99,
    "batch_size": 64,
    "checkpoint_freq": 10,
    "debug": false,
    "display_logging": true,
    "drop_mlp": 0.0,
    "drop_path": 0.0,
    "dropout": 0.1,
    "ema": [
        0.996,
        0.999
    ],
    "emb_dim": 1024,
    "embedding_skip_connections": true,
    "encoder_depth": 24,
    "eps": 1e-07,
    "event_info_file": "",
    "hidden_features": 512,
    "in_features": 1024,
    "init_std": 0.02,
    "initial_embedding_dim": 256,
    "initial_embedding_skip_connections": false,
    "input_dim": 120,
    "learning_rate": 0.0001,
    "linear_block_type": "basic",
    "log_freq": 10,
    "lr": 0.0001,
    "max_grad_norm": 0.1,
    "min_lr": 1e-06,
    "mlp_ratio": 1.0,
    "normalization": "LayerNorm",
    "num_context_subjets": 10,
    "num_embedding_layers": 10,
    "num_epochs": 300,
    "num_heads": 16,
    "num_jets": 1200000,
    "num_layers": 6,
    "num_part_ftr": 4,
    "num_particles": 30,
    "num_subjets": 20,
    "num_val_jets": 400000,
    "num_workers": 0,
    "optimizer": "AdamW",
    "out_features": 1024,
    "pred_depth": 12,
    "predictor_emb_dim": 128,
    "proj_drop": 0.0,
    "qk_scale": null,
    "qkv_bias": true,
    "repr_dim": -1,
    "scheduler": "cosine",
    "skip_connections": true,
    "start_epochs": 0,
    "testing_file": "",
    "training_file": "",
    "use_amp": false,
    "use_predictor": true,
    "validation_file": "",
    "warmup_epochs": 10,
    "warmup_start_lr": 1e-08,
    "weight_decay": 0.01
}
